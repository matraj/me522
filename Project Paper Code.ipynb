{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 522 Project Code\n",
    "Chang Li, Maathusan Rajendram, Anastasia Santasheva, Evan Yeung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard useful packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# validation & normalization methods\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "\n",
    "# accuracy, MSE, log loss & timer methods\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from time import time\n",
    "\n",
    "# dim reduction & classification methods \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "# make matplotlib to show plots inline\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configuration\n",
    "* Select options for method validation\n",
    "* Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. set dataset\n",
    "ENABLE_POR_DATA = True     # set Portugese course dataset\n",
    "ENABLE_MAT_DATA = False    # set Math course dataset\n",
    "\n",
    "# 2. set supervised approach for G3\n",
    "ENABLE_BINARY_TARGET = False       # sets G3 to binary\n",
    "ENABLE_5LEVEL_TARGET = False        # set G3 to five-level scale\n",
    "ENABLE_REGRESSION_TARGET = True   # set G3 to current state for regression\n",
    "\n",
    "# 3. set dimensionaltiy reduction method - set both to false for none\n",
    "ENABLE_PCN = False\n",
    "ENABLE_LDA = False\n",
    "\n",
    "# 4. set validation type\n",
    "ENABLE_KFOLD = True\n",
    "ENABLE_LOO = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load  Dataset\n",
    "* Select a data set (Portugese course or Math course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((519, 33), (130, 33))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from csv\n",
    "if (ENABLE_POR_DATA):\n",
    "    dataframe = pd.read_csv('student-por-train.csv', usecols = range(0,33)) \n",
    "    dataframe_test = pd.read_csv('student-por-test.csv', usecols = range(0,33)) \n",
    "elif (ENABLE_MAT_DATA): \n",
    "    dataframe = pd.read_csv('student-mat-train.csv', usecols = range(0,33))\n",
    "    dataframe_test = pd.read_csv('student-mat-test.csv', usecols = range(0,33))\n",
    "\n",
    "dataset = dataframe.values\n",
    "dataset_test = dataframe_test.values\n",
    "dataset.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "* Convert nominal attributes with Integer + One-Hot Encoding\n",
    "* Selects supervised approache for G3\n",
    "* NOTE: if we want we can also split further into A,B,C (A= all cols, B=same as A without G2, C=same as B without G1)\n",
    "    * But leaving this out for now since we know A gives best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# helper functions for preprocessing\n",
    "def convertToBinary(df, num_cols):\n",
    "    df.loc[(df.G3 < 10), 'G3'] = 0\n",
    "    df.loc[(df.G3 >= 10), 'G3'] = 1\n",
    "    \n",
    "    G3 = df.values[:,num_cols-1]\n",
    "    return G3\n",
    "\n",
    "def convertToFiveLevel(df, num_cols):\n",
    "    df.loc[(df.G3 <= 9), 'G3'] = 0\n",
    "    df.loc[(df.G3 > 9) & (df.G3 <= 11), 'G3'] = 1\n",
    "    df.loc[(df.G3 > 11) & (df.G3 <= 13), 'G3'] = 2\n",
    "    df.loc[(df.G3 > 13) & (df.G3 <= 16), 'G3'] = 3\n",
    "    df.loc[(df.G3 > 16), 'G3'] = 4\n",
    "    \n",
    "    G3 = df.values[:,num_cols-1]\n",
    "    return G3   \n",
    "\n",
    "def oneHotEncode(df, num_cols):\n",
    "    df = df.drop(labels='G3', axis=1)\n",
    "    cols_to_transform = [\n",
    "                        'school',\n",
    "                        'sex',\n",
    "                        'address',\n",
    "                        'famsize',\n",
    "                        'Pstatus',\n",
    "                        'Mjob',                        \n",
    "                        'Fjob',\n",
    "                        'reason',\n",
    "                        'guardian',\n",
    "                        'famsup',\n",
    "                        'schoolsup',\n",
    "                        'paid',\n",
    "                        'activities',\n",
    "                        'nursery',                        \n",
    "                        'higher',\n",
    "                        'internet',\n",
    "                        'romantic',\n",
    "                        ]\n",
    "    hot_encoded_df = pd.get_dummies(df, columns = cols_to_transform)\n",
    "    \n",
    "    attributes = hot_encoded_df.values\n",
    "    return attributes\n",
    "\n",
    "def normalizeData(train_data, val_data, test_data):\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data = scaler.transform(train_data)\n",
    "    val_data = scaler.transform(val_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# shuffle dataset\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# find col length\n",
    "num_cols = dataset.shape[1]\n",
    "\n",
    "# split one-hot encoded attributes (X) and G3 (Y)\n",
    "X = oneHotEncode(dataframe, num_cols)\n",
    "X_tst = oneHotEncode(dataframe_test, num_cols)\n",
    "\n",
    "# selects supervised approach for G3\n",
    "if (ENABLE_BINARY_TARGET):\n",
    "    Y = convertToBinary(dataframe, num_cols).astype('int')\n",
    "    Y_tst = convertToBinary(dataframe_test, num_cols).astype('int')\n",
    "elif (ENABLE_5LEVEL_TARGET):\n",
    "    Y = convertToFiveLevel(dataframe, num_cols).astype('int')\n",
    "    Y_tst = convertToFiveLevel(dataframe_test, num_cols).astype('int')\n",
    "elif (ENABLE_REGRESSION_TARGET):\n",
    "    Y = dataset[:,num_cols-1].astype('int')\n",
    "    Y_tst = dataset_test[:,num_cols-1].astype('int')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((519, 58), (519,), (130, 58), (130,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y\n",
    "X.shape, Y.shape, X_tst.shape, Y_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "* PCA & LDA reduction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaReduction(train_data, val_data, test_data, n_comp):\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    train_data = pca.fit_transform(train_data)\n",
    "    val_data = pca.transform(val_data)\n",
    "    test_data = pca.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def ldaReduction(train_data, train_target, val_data, test_data, n_comp):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_comp)\n",
    "    train_data = lda.fit_transform(train_data, train_target)\n",
    "    val_data = lda.transform(val_data)\n",
    "    test_data = lda.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Methods\n",
    "* k-Fold cross validation & Leave-one-out validation\n",
    "* data gets normalized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to calculate accuracy (PCC) & RMSE\n",
    "def calcMetric(actual, predicted):\n",
    "    if(ENABLE_REGRESSION_TARGET): return (mean_squared_error(actual, predicted))**(0.5) # calculates RMSE\n",
    "    else: return accuracy_score(actual, predicted, normalize = True) # calculates PCC\n",
    "\n",
    "def kFoldValidation(n_comp, penalty, n_splits=10):\n",
    "    kFold = KFold(n_splits=n_splits)\n",
    "    \n",
    "    # run on test data\n",
    "    test_results = []\n",
    "    val_results = []\n",
    "    train_results = []\n",
    "    log_loss_results = []\n",
    "    time_log = []\n",
    "    \n",
    "    for train_index, val_index in kFold.split(X):\n",
    "        #start timer, return avg time below\n",
    "        start = time()\n",
    "        \n",
    "        X_train, X_val, X_test = X[train_index], X[val_index], X_tst\n",
    "        Y_train, Y_val, Y_test = Y[train_index], Y[val_index], Y_tst\n",
    "        \n",
    "        # normalize data\n",
    "        X_train, X_val, X_test = normalizeData(X_train, X_val, X_test)\n",
    "        \n",
    "        # reduce dimensionality\n",
    "        if (ENABLE_PCN): X_train, X_val, X_test = pcaReduction(X_train, X_val, X_test, n_comp)\n",
    "        elif (ENABLE_LDA): X_train, X_val, X_test = ldaReduction(X_train, Y_train, X_val, X_test, n_comp)\n",
    "        \n",
    "        # build classifier for each set\n",
    "        clf = buildClf(X_train, Y_train, penalty)\n",
    "        \n",
    "        predicted = clf.predict(X_test)\n",
    "        test_accuracy = calcMetric(Y_test, predicted)\n",
    "        predicted = clf.predict(X_val)\n",
    "        val_accuracy = calcMetric(Y_val, predicted)\n",
    "        predicted = clf.predict(X_train)\n",
    "        train_accuracy = calcMetric(Y_train, predicted)\n",
    "        \n",
    "        # log loss calculation - for classification only\n",
    "        if(not ENABLE_REGRESSION_TARGET): log_loss_results.append(log_loss(Y_val, clf.predict_proba(X_val)))\n",
    "        \n",
    "        test_results.append(test_accuracy)\n",
    "        val_results.append(val_accuracy)\n",
    "        train_results.append(train_accuracy)\n",
    "        time_log.append(time()-start)\n",
    "        \n",
    "    return np.mean(train_results, axis = 0), np.mean(val_results, axis = 0), np.mean(test_results, axis = 0), np.mean(log_loss_results, axis = 0), np.mean(time_log, axis = 0)\n",
    "\n",
    "def looValidation(n_comp, penalty):\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    # run on test data\n",
    "    test_results = []\n",
    "    val_results = []\n",
    "    train_results = []\n",
    "    Y_test_prob = []\n",
    "    log_loss_value = 0\n",
    "    time_log = []\n",
    "    \n",
    "    for train_index, val_index in loo.split(X):\n",
    "        #start timer, return avg time below\n",
    "        start = time()\n",
    "        \n",
    "        X_train, X_val, X_test = X[train_index], X[val_index], X_tst\n",
    "        Y_train, Y_val, Y_test = Y[train_index], Y[val_index], Y_tst\n",
    "        \n",
    "        # normalize data\n",
    "        X_train, X_val, X_test = normalizeData(X_train, X_val, X_test)\n",
    "        \n",
    "        # reduce dimensionality\n",
    "        if (ENABLE_PCN): X_train, X_val, X_test = pcaReduction(X_train, X_val, X_test, n_comp)\n",
    "        elif (ENABLE_LDA): X_train, X_val, X_test = ldaReduction(X_train, Y_train, X_val, X_test, n_comp)\n",
    "        \n",
    "        # build classifier for each set\n",
    "        clf = buildClf(X_train, Y_train, penalty)\n",
    "        \n",
    "        predicted = clf.predict(X_test)\n",
    "        test_accuracy = calcMetric(Y_test, predicted)\n",
    "        predicted = clf.predict(X_val)\n",
    "        val_accuracy = calcMetric(Y_val, predicted)\n",
    "        predicted = clf.predict(X_train)\n",
    "        train_accuracy = calcMetric(Y_train, predicted)\n",
    "        \n",
    "        # save probability for log loss calculation\n",
    "        if(not ENABLE_REGRESSION_TARGET): Y_test_prob.append(clf.predict_proba(X_val)[0])\n",
    "            \n",
    "        test_results.append(test_accuracy)\n",
    "        val_results.append(val_accuracy)\n",
    "        train_results.append(train_accuracy)\n",
    "        time_log.append(time()-start)\n",
    "    \n",
    "    # log loss calculation - for classification only\n",
    "    if(not ENABLE_REGRESSION_TARGET): log_loss_value = log_loss(Y, Y_test_prob)\n",
    "\n",
    "    return np.mean(train_results, axis = 0), np.mean(val_results, axis = 0), np.mean(test_results, axis = 0), log_loss_value, np.mean(time_log, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Selection\n",
    "* Select classifer to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVotingClassifier():\n",
    "    clf1 = SVC(C=10000, probability=True, kernel='rbf', gamma=0.0001)\n",
    "    clf2 = RandomForestClassifier(n_estimators = 100, criterion = \"entropy\")\n",
    "    clf3 = GaussianNB()\n",
    "\n",
    "    return VotingClassifier(estimators=[('svm', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "\n",
    "# method to build classifier\n",
    "def buildClf(train_data, train_target, penalty):\n",
    "    \n",
    "    if(ENABLE_REGRESSION_TARGET):\n",
    "        model = SVR(C=1.0, kernel='rbf', gamma=penalty) # for regression\n",
    "    else:\n",
    "        model = SVC(C=penalty, probability=True, kernel='linear')\n",
    "#         model = getVotingClassifier()\n",
    "#         model = GaussianNB()\n",
    "#         model = MLPClassifier(solver = 'lbfgs')\n",
    "#         model = DecisionTreeClassifier(max_depth = None, max_features = penalty, criterion = \"entropy\")\n",
    "#         model = RandomForestClassifier(n_estimators = penalty, max_features=450, criterion = \"entropy\")\n",
    "#         model = KNeighborsClassifier(n_neighbors=penalty, p=1)\n",
    "#         model = BaggingClassifier(DecisionTreeClassifier(max_features = penalty, criterion = \"entropy\"), max_samples=0.5, max_features=6)\n",
    "\n",
    "    model.fit(train_data, train_target)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Accuracy, Log Loss & Error\n",
    "* Adjust array of penalty parameters\n",
    "* Graphs error and log loss - for classification only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----C=0.001953125-----\n",
      "Time: 0.0517733097076416 seconds\n",
      "-----Train-----\n",
      "Accuracy/RMSE: 3.111122685809477\n",
      "-----Validation-----\n",
      "Accuracy/RMSE: 3.2107062003090183\n",
      "Log Loss: nan\n",
      "\n",
      "-----C=0.0078125-----\n",
      "Time: 0.04657905101776123 seconds\n",
      "-----Train-----\n",
      "Accuracy/RMSE: 2.975061293583207\n",
      "-----Validation-----\n",
      "Accuracy/RMSE: 3.2215770479904022\n",
      "Log Loss: nan\n",
      "\n",
      "-----C=0.03125-----\n",
      "Time: 0.051230454444885255 seconds\n",
      "-----Train-----\n",
      "Accuracy/RMSE: 2.6190548039596906\n",
      "-----Validation-----\n",
      "Accuracy/RMSE: 3.2029686000862205\n",
      "Log Loss: nan\n",
      "\n",
      "-----C=0.125-----\n",
      "Time: 0.05272941589355469 seconds\n",
      "-----Train-----\n",
      "Accuracy/RMSE: 2.5168979301827528\n",
      "-----Validation-----\n",
      "Accuracy/RMSE: 3.187252405394363\n",
      "Log Loss: nan\n",
      "\n",
      "-----C=0.5-----\n",
      "Time: 0.05706014633178711 seconds\n",
      "-----Train-----\n",
      "Accuracy/RMSE: 2.514715864451852\n",
      "-----Validation-----\n",
      "Accuracy/RMSE: 3.184364677858811\n",
      "Log Loss: nan\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a94e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input reduced dimension - this can be ignored if none selected\n",
    "n_comp = 1\n",
    "\n",
    "# input penalty iterations - can tune other params in classifer selection method above\n",
    "# hyperparams = [None]\n",
    "# hyperparams = [1, 10, 100, 1000, 10000]\n",
    "hyperparams = [2**(-9), 2**(-7), 2**(-5), 2**(-3), 2**(-1)]\n",
    "\n",
    "# results array format: [[train], [validation], [test], [log loss]]\n",
    "results = [[],[],[],[]]\n",
    "\n",
    "# calculate train error, test error, log loss & time for specific param\n",
    "for penalty in hyperparams:\n",
    "    \n",
    "    if (ENABLE_KFOLD): train_res, val_res, test_res, log_loss_val, time_val = kFoldValidation(n_comp, penalty, 10)\n",
    "    elif (ENABLE_LOO): train_res, val_res, test_res, log_loss_val, time_val = looValidation(n_comp, penalty)\n",
    "    \n",
    "    # save error, RMSE, log loss for each penalty for graph\n",
    "    if (not ENABLE_REGRESSION_TARGET):\n",
    "        results[0].append(1-train_res)\n",
    "        results[1].append(1-val_res)\n",
    "        results[2].append(1-test_res)\n",
    "        results[3].append(log_loss_val)\n",
    "    elif (ENABLE_REGRESSION_TARGET):\n",
    "        results[0].append(train_res)\n",
    "        results[1].append(val_res)\n",
    "\n",
    "    print (\"-----C={}-----\".format(penalty))\n",
    "    print (\"Time: {} seconds\".format(time_val))\n",
    "    print (\"-----Train-----\")\n",
    "    print (\"Accuracy/RMSE: {}\".format(train_res))\n",
    "    print (\"-----Validation-----\")\n",
    "    print (\"Accuracy/RMSE: {}\".format(val_res))\n",
    "#     print (\"-----Test-----\")\n",
    "#     print (\"Accuracy/RMSE: {}\".format(test_res))\n",
    "    print (\"Log Loss: {}\\n\".format(log_loss_val))\n",
    "        \n",
    "# create error and log loss graph for penalty iterations - classification only\n",
    "if(not ENABLE_REGRESSION_TARGET and len(hyperparams) > 1):\n",
    "    f, axarr = plt.subplots(2, sharex=False)\n",
    "    f.suptitle('Error and Log Loss', y = 0.92)\n",
    "    f.set_size_inches(10, 10)\n",
    "\n",
    "    # subplot 1: error plot\n",
    "    axarr[0].set_ylabel('Error')\n",
    "    axarr[0].plot(hyperparams, results[0], color='r', label='train')\n",
    "    axarr[0].plot(hyperparams, results[1], color='b', label='validation')\n",
    "    axarr[0].set_xticks(hyperparams)\n",
    "    axarr[0].legend()\n",
    "\n",
    "    # subplot 2: log loss plot\n",
    "    axarr[1].set_ylabel('Log Loss')\n",
    "    axarr[1].plot(hyperparams, results[3], color='g', label='log loss')\n",
    "    axarr[1].set_xticks(hyperparams)\n",
    "    axarr[1].set_xlabel('Penalty')\n",
    "    plt.show()\n",
    "    \n",
    "# create RMSE graph for penalty iterations - regression only\n",
    "if(ENABLE_REGRESSION_TARGET and len(hyperparams) > 1):\n",
    "    f, axarr = plt.subplots(sharex=False)\n",
    "    f.suptitle('RMSE', y = 0.92)\n",
    "    f.set_size_inches(10, 5)\n",
    "\n",
    "    # subplot 1: RMSE plot\n",
    "    axarr.set_ylabel('RMSE')\n",
    "    axarr.plot(hyperparams, results[0], color='r', label='train')\n",
    "    axarr.plot(hyperparams, results[1], color='b', label='validation')\n",
    "    axarr.set_xticks(hyperparams)\n",
    "    axarr.set_xlabel('Parameter')\n",
    "    axarr.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
